{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import open3d\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import demo as demo\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import DatasetTemplate\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "\n",
    "# 3 tool class, PillarVFE, PFNLayer, PointPillarScatter\n",
    "from pcdet.models.backbones_3d.vfe import pillar_vfe as VFE\n",
    "from pcdet.models.backbones_2d.map_to_bev import pointpillar_scatter as Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 16:46:59,821   INFO  Test to get the VFE params2023-12-14 16:46:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} {'_BASE_CONFIG_': '/home/ghosnp/project/s4_exp/OpenPCDet/tools/cfgs/dataset_configs/kitti_dataset.yaml', 'POINT_CLOUD_RANGE': [-69.12, -39.68, -3, 69.12, 39.68, 1], 'DATA_PROCESSOR': [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.16, 0.16, 4], 'MAX_POINTS_PER_VOXEL': 32, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}], 'DATA_AUGMENTOR': {'DISABLE_AUG_LIST': ['placeholder'], 'AUG_CONFIG_LIST': [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]}}\n",
      "{'DISABLE_AUG_LIST': ['placeholder'], 'AUG_CONFIG_LIST': [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:20', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]} {'DISABLE_AUG_LIST': ['placeholder'], 'AUG_CONFIG_LIST': [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]}\n",
      "{} {'NAME': 'PointPillar', 'VFE': {'NAME': 'PillarVFE', 'WITH_DISTANCE': False, 'USE_ABSLOTE_XYZ': True, 'USE_NORM': True, 'NUM_FILTERS': [64]}, 'MAP_TO_BEV': {'NAME': 'PointPillarScatter', 'NUM_BEV_FEATURES': 64}, 'BACKBONE_2D': {'NAME': 'BaseBEVBackbone', 'LAYER_NUMS': [3, 5, 5], 'LAYER_STRIDES': [2, 2, 2], 'NUM_FILTERS': [64, 128, 256], 'UPSAMPLE_STRIDES': [1, 2, 4], 'NUM_UPSAMPLE_FILTERS': [128, 128, 128]}, 'DENSE_HEAD': {'NAME': 'AnchorHeadSingle', 'CLASS_AGNOSTIC': False, 'USE_DIRECTION_CLASSIFIER': True, 'DIR_OFFSET': 0.78539, 'DIR_LIMIT_OFFSET': 0.0, 'NUM_DIR_BINS': 2, 'ANCHOR_GENERATOR_CONFIG': [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}], 'TARGET_ASSIGNER_CONFIG': {'NAME': 'AxisAlignedTargetAssigner', 'POS_FRACTION': -1.0, 'SAMPLE_SIZE': 512, 'NORM_BY_NUM_EXAMPLES': False, 'MATCH_HEIGHT': False, 'BOX_CODER': 'ResidualCoder'}, 'LOSS_CONFIG': {'LOSS_WEIGHTS': {'cls_weight': 1.0, 'loc_weight': 2.0, 'dir_weight': 0.2, 'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}}, 'POST_PROCESSING': {'RECALL_THRESH_LIST': [0.3, 0.5, 0.7], 'SCORE_THRESH': 0.1, 'OUTPUT_RAW_SCORE': False, 'EVAL_METRIC': 'kitti', 'NMS_CONFIG': {'MULTI_CLASSES_NMS': False, 'NMS_TYPE': 'nms_gpu', 'NMS_THRESH': 0.01, 'NMS_PRE_MAXSIZE': 4096, 'NMS_POST_MAXSIZE': 500}}}\n",
      "{} {'NAME': 'PillarVFE', 'WITH_DISTANCE': False, 'USE_ABSLOTE_XYZ': True, 'USE_NORM': True, 'NUM_FILTERS': [64]}\n",
      "{} {'NAME': 'PointPillarScatter', 'NUM_BEV_FEATURES': 64}\n",
      "{} {'NAME': 'BaseBEVBackbone', 'LAYER_NUMS': [3, 5, 5], 'LAYER_STRIDES': [2, 2, 2], 'NUM_FILTERS': [64, 128, 256], 'UPSAMPLE_STRIDES': [1, 2, 4], 'NUM_UPSAMPLE_FILTERS': [128, 128, 128]}\n",
      "{} {'NAME': 'AnchorHeadSingle', 'CLASS_AGNOSTIC': False, 'USE_DIRECTION_CLASSIFIER': True, 'DIR_OFFSET': 0.78539, 'DIR_LIMIT_OFFSET': 0.0, 'NUM_DIR_BINS': 2, 'ANCHOR_GENERATOR_CONFIG': [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}], 'TARGET_ASSIGNER_CONFIG': {'NAME': 'AxisAlignedTargetAssigner', 'POS_FRACTION': -1.0, 'SAMPLE_SIZE': 512, 'NORM_BY_NUM_EXAMPLES': False, 'MATCH_HEIGHT': False, 'BOX_CODER': 'ResidualCoder'}, 'LOSS_CONFIG': {'LOSS_WEIGHTS': {'cls_weight': 1.0, 'loc_weight': 2.0, 'dir_weight': 0.2, 'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}}\n",
      "{} {'NAME': 'AxisAlignedTargetAssigner', 'POS_FRACTION': -1.0, 'SAMPLE_SIZE': 512, 'NORM_BY_NUM_EXAMPLES': False, 'MATCH_HEIGHT': False, 'BOX_CODER': 'ResidualCoder'}\n",
      "{} {'LOSS_WEIGHTS': {'cls_weight': 1.0, 'loc_weight': 2.0, 'dir_weight': 0.2, 'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}\n",
      "{} {'cls_weight': 1.0, 'loc_weight': 2.0, 'dir_weight': 0.2, 'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
      "{} {'RECALL_THRESH_LIST': [0.3, 0.5, 0.7], 'SCORE_THRESH': 0.1, 'OUTPUT_RAW_SCORE': False, 'EVAL_METRIC': 'kitti', 'NMS_CONFIG': {'MULTI_CLASSES_NMS': False, 'NMS_TYPE': 'nms_gpu', 'NMS_THRESH': 0.01, 'NMS_PRE_MAXSIZE': 4096, 'NMS_POST_MAXSIZE': 500}}\n",
      "{} {'MULTI_CLASSES_NMS': False, 'NMS_TYPE': 'nms_gpu', 'NMS_THRESH': 0.01, 'NMS_PRE_MAXSIZE': 4096, 'NMS_POST_MAXSIZE': 500}\n",
      "{} {'BATCH_SIZE_PER_GPU': 4, 'NUM_EPOCHS': 80, 'OPTIMIZER': 'adam_onecycle', 'LR': 0.003, 'WEIGHT_DECAY': 0.01, 'MOMENTUM': 0.9, 'MOMS': [0.95, 0.85], 'PCT_START': 0.4, 'DIV_FACTOR': 10, 'DECAY_STEP_LIST': [35, 45], 'LR_DECAY': 0.1, 'LR_CLIP': 1e-07, 'LR_WARMUP': False, 'WARMUP_EPOCH': 1, 'GRAD_NORM_CLIP': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghosnp/miniconda3/envs/pcdet/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "2023-12-14 16:47:01,759   INFO  ==> Loading parameters from checkpoint ../self_ckpts/pointpillar_7728.pth to CPU\n",
      "2023-12-14 16:47:01,776   INFO  ==> Done (loaded 127/127)\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = '../self_ckpts/pointpillar_7728.pth'\n",
    "cfg_path = './cfgs/kitti_models/pointpillar.yaml'\n",
    "data_path = '/home/ghosnp/dataset/mini_kitti/velodyne/selected/000005.bin'\n",
    "txt_path = '/home/ghosnp/dataset/mini_kitti/label_2/selected/000005.txt'\n",
    "\n",
    "\n",
    "logger = common_utils.create_logger()   # logger.info('xxx')\n",
    "# common_utils.set_random_seed(66)\n",
    "logger.info('Test to get the VFE params' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "cfg_from_yaml_file(cfg_path, cfg)\n",
    "\n",
    "\n",
    "demo_dataset = demo.DemoDataset(\n",
    "    dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, training=False,\n",
    "    root_path=Path(data_path), ext='.bin', logger=logger\n",
    ")\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=demo_dataset)\n",
    "model.load_params_from_file(filename=ckpt_path, logger=logger, to_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NAME': 'PointPillar', 'VFE': {'NAME': 'PillarVFE', 'WITH_DISTANCE': False, 'USE_ABSLOTE_XYZ': True, 'USE_NORM': True, 'NUM_FILTERS': [64]}, 'MAP_TO_BEV': {'NAME': 'PointPillarScatter', 'NUM_BEV_FEATURES': 64}, 'BACKBONE_2D': {'NAME': 'BaseBEVBackbone', 'LAYER_NUMS': [3, 5, 5], 'LAYER_STRIDES': [2, 2, 2], 'NUM_FILTERS': [64, 128, 256], 'UPSAMPLE_STRIDES': [1, 2, 4], 'NUM_UPSAMPLE_FILTERS': [128, 128, 128]}, 'DENSE_HEAD': {'NAME': 'AnchorHeadSingle', 'CLASS_AGNOSTIC': False, 'USE_DIRECTION_CLASSIFIER': True, 'DIR_OFFSET': 0.78539, 'DIR_LIMIT_OFFSET': 0.0, 'NUM_DIR_BINS': 2, 'ANCHOR_GENERATOR_CONFIG': [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}], 'TARGET_ASSIGNER_CONFIG': {'NAME': 'AxisAlignedTargetAssigner', 'POS_FRACTION': -1.0, 'SAMPLE_SIZE': 512, 'NORM_BY_NUM_EXAMPLES': False, 'MATCH_HEIGHT': False, 'BOX_CODER': 'ResidualCoder'}, 'LOSS_CONFIG': {'LOSS_WEIGHTS': {'cls_weight': 1.0, 'loc_weight': 2.0, 'dir_weight': 0.2, 'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}}, 'POST_PROCESSING': {'RECALL_THRESH_LIST': [0.3, 0.5, 0.7], 'SCORE_THRESH': 0.1, 'OUTPUT_RAW_SCORE': False, 'EVAL_METRIC': 'kitti', 'NMS_CONFIG': {'MULTI_CLASSES_NMS': False, 'NMS_TYPE': 'nms_gpu', 'NMS_THRESH': 0.01, 'NMS_PRE_MAXSIZE': 4096, 'NMS_POST_MAXSIZE': 500}}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import kornia\n",
    "\n",
    "voxel_size = torch.tensor([0.16, 0.16, 4])\n",
    "pc_range = torch.tensor([-69.12, -39.68, -3., 69.12, 39.68, 1.])\n",
    "\n",
    "def trans_data_2_tensor(batch_dict):\n",
    "    for key, val in batch_dict.items():\n",
    "        if key == 'camera_imgs':\n",
    "            batch_dict[key] = val.cuda()\n",
    "        elif not isinstance(val, np.ndarray):\n",
    "            continue\n",
    "        elif key in ['frame_id', 'metadata', 'calib', 'image_paths','ori_shape','img_process_infos']:\n",
    "            continue\n",
    "        elif key in ['images']:\n",
    "            batch_dict[key] = kornia.image_to_tensor(val).float()\n",
    "        elif key in ['image_shape']:\n",
    "            batch_dict[key] = torch.from_numpy(val).int()\n",
    "        else:\n",
    "            batch_dict[key] = torch.from_numpy(val).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, data_dict in enumerate(demo_dataset):\n",
    "        data_dict = demo_dataset.collate_batch([data_dict])\n",
    "        trans_data_2_tensor(data_dict)\n",
    "\n",
    "model_cfg = model.model_cfg\n",
    "print(model_cfg)\n",
    "num_point_features = model_cfg.VFE.NUM_FILTERS\n",
    "num_point_features = 4\n",
    "\n",
    "in_channels = 10\n",
    "out_channels = 64\n",
    "use_norm = True\n",
    "last_layer = True\n",
    "grid_size = [(pc_range[3] - pc_range[0]) / voxel_size[0], (pc_range[4] - pc_range[1]) / voxel_size[1], 1]\n",
    "grid_size = torch.tensor(grid_size).int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class isPointInQuadrangle(object):\n",
    "\n",
    "    def __int__(self):\n",
    "        self.__isInQuadrangleFlag = False\n",
    "\n",
    "    def cross_product(self, xp, yp, x1, y1, x2, y2):\n",
    "        return (x2 - x1) * (yp - y1)-(y2 - y1) * (xp - x1)\n",
    "\n",
    "    def compute_para(self, xp, yp, xa, ya, xb, yb, xc, yc, xd, yd):\n",
    "        cross_product_ab = isPointInQuadrangle().cross_product(xp, yp, xa, ya, xb, yb)\n",
    "        cross_product_bc = isPointInQuadrangle().cross_product(xp, yp, xb, yb, xc, yc)\n",
    "        cross_product_cd = isPointInQuadrangle().cross_product(xp, yp, xc, yc, xd, yd)\n",
    "        cross_product_da = isPointInQuadrangle().cross_product(xp, yp, xd, yd, xa, ya)\n",
    "        return cross_product_ab,cross_product_bc,cross_product_cd,cross_product_da\n",
    "\n",
    "    def is_in_rect(self, aa, bb, cc, dd):\n",
    "        if (aa > 0 and bb > 0 and cc > 0 and dd > 0) or (aa < 0 and bb < 0 and cc < 0 and dd < 0):\n",
    "            self.__isInQuadrangleFlag= True\n",
    "        else:\n",
    "            self.__isInQuadrangleFlag = False\n",
    "\n",
    "        return self.__isInQuadrangleFlag\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aa, bb, cc, dd = isPointInQuadrangle().compute_para(600, 550, 508, 451, 730, 470, 718, 615, 495, 596)\n",
    "    print(isPointInQuadrangle().is_in_rect(aa, bb, cc, dd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, torch.Size([1, 64, 496, 864])\n",
      "tensor([[  0.,   0., 291., 526.],\n",
      "        [  0.,   0., 291., 525.],\n",
      "        [  0.,   0., 292., 525.],\n",
      "        ...,\n",
      "        [  0.,   0., 236., 453.],\n",
      "        [  0.,   0., 236., 454.],\n",
      "        [  0.,   0., 238., 454.]])\n",
      "tensor(3352962., grad_fn=<SumBackward1>)\n",
      "tensor(3352962., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pillarVFE = VFE.PillarVFE(model_cfg=model_cfg.VFE, num_point_features=num_point_features, voxel_size=voxel_size, point_cloud_range=pc_range)\n",
    "pillarVFE.forward(data_dict)\n",
    "\n",
    "pillarScatter = Scatter.PointPillarScatter(model_cfg=model_cfg.MAP_TO_BEV, grid_size=grid_size)\n",
    "pillarScatter.forward(data_dict)\n",
    "\n",
    "print('Done,',data_dict['spatial_features'].shape)\n",
    "print(data_dict['voxel_coords'])\n",
    "\n",
    "sum_all_pillar_features = torch.sum(data_dict['pillar_features'], dim=0)\n",
    "sumsum_pillar_features = torch.sum(sum_all_pillar_features, dim=0)\n",
    "print(sumsum_pillar_features)\n",
    "\n",
    "sum_spatial_features = torch.sum(data_dict['spatial_features'])\n",
    "print(sum_spatial_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[574 299]\n",
      " [574 300]\n",
      " [574 301]\n",
      " [574 302]\n",
      " [574 303]\n",
      " [575 299]\n",
      " [575 300]\n",
      " [575 301]\n",
      " [575 302]\n",
      " [575 303]\n",
      " [576 299]\n",
      " [576 300]\n",
      " [576 301]\n",
      " [576 302]\n",
      " [576 303]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pcd_path = '/home/ghosnp/dataset/mini_kitti/velodyne/training/velodyne/000011.bin'\n",
    "# txt_path = '/home/ghosnp/dataset/mini_kitti/label_2/training/label_2/000011.txt'\n",
    "POINT_CLOUD_RANGE = np.array([-69.12, -39.68, -3, 69.12, 39.68, 1], dtype=np.float32)\n",
    "\n",
    "with open(txt_path, 'r') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "pcd = np.fromfile(data_path, dtype=np.float32).reshape(-1, 4)\n",
    "corners_bevs = []\n",
    "corners_3Ds = []\n",
    "\n",
    "\n",
    "\n",
    "for line in txt:\n",
    "    line = line.split()\n",
    "    lab, x, y, z, w, l, h, rot = line[0], line[11], line[12], line[13], line[9], line[10], line[8], line[14]\n",
    "    h, w, l, x, y, z, rot = map(float, [h, w, l, x, y, z, rot])\n",
    "    \n",
    "    if lab != 'DontCare':\n",
    "        x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2]\n",
    "        y_corners = [0, 0, 0, 0, -h, -h, -h, -h]\n",
    "        z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2]\n",
    "        corners_3d = np.vstack([x_corners, y_corners, z_corners])  # (3, 8)\n",
    "\n",
    "        # transform the 3d bbox from object coordiante to camera_0 coordinate\n",
    "        R = np.array([[np.cos(rot), 0, np.sin(rot)],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(rot), 0, np.cos(rot)]])\n",
    "   \n",
    "        corners_3d = np.dot(R, corners_3d).T + np.array([x, y, z])\n",
    "\n",
    "        # transform the 3d bbox from camera_0 coordinate to velodyne coordinate\n",
    "        corners_3d = corners_3d[:, [2, 0, 1]] * np.array([[1, -1, -1]])\n",
    "        corners_3Ds.append(corners_3d)\n",
    "        corners_bevs.append(corners_3d[:4, [0, 1]])\n",
    "        \n",
    "corners_bevs = np.array(corners_bevs)\n",
    "\n",
    "# corners_bevs add range offset\n",
    "corners_bevs[:, :, 0] += POINT_CLOUD_RANGE[3]\n",
    "corners_bevs[:, :, 1] += POINT_CLOUD_RANGE[4]\n",
    "corners_bevs /= 0.16\n",
    "\n",
    "\n",
    "feature_idx = []\n",
    "tool = isPointInQuadrangle()\n",
    "# Get the index in the range of corners_bevs\n",
    "for corners in corners_bevs:\n",
    "\n",
    "    vector01 = corners[1] - corners[0]\n",
    "    vector03 = corners[3] - corners[0]\n",
    "    square_area = np.linalg.norm(vector01) * np.linalg.norm(vector03)\n",
    "    max_x, min_x, max_y, min_y = np.max(corners[:,0]), np.min(corners[:,0]), np.max(corners[:,1]), np.min(corners[:,1])\n",
    "    max_x, min_x, max_y, min_y = int(max_x), int(min_x), int(max_y), int(min_y)\n",
    "    # get x,y with (min_x < x < max_x and min_y < y < max_y)\n",
    "    x = np.arange(min_x, max_x)\n",
    "    y = np.arange(min_y, max_y)\n",
    "    print(x,y)\n",
    "    temp_add = []\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            a, b, c, d = tool.compute_para(i, j, corners[0][0], corners[0][1], corners[1][0], corners[1][1], corners[2][0], corners[2][1], corners[3][0], corners[3][1])\n",
    "            res = tool.is_in_rect(a, b, c, d)\n",
    "            if res:\n",
    "                feature_idx.append([i, j])\n",
    "                temp_add.append([i, j])\n",
    "    \n",
    "feature_idx = np.array(feature_idx)\n",
    "print(feature_idx)\n",
    "\n",
    "# visualize the block with feature_idx\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "for corners_bev in corners_bevs:\n",
    "    plt.plot(corners_bev[:,0], corners_bev[:,1], 'r-')\n",
    "plt.scatter(feature_idx[:,0], feature_idx[:,1], s=1)\n",
    "plt.xlim(0, 864)\n",
    "plt.ylim(0, 864)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(756.9105, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# feature_idx load to gpu\n",
    "feature_idx_gpu = torch.from_numpy(feature_idx).cuda()\n",
    "# load the spatial_features\n",
    "spatial_features_gpu = data_dict['spatial_features'][0]\n",
    "# get the feature with feature_idx\n",
    "valid_features_gpu = spatial_features_gpu[:, feature_idx_gpu[:,1], feature_idx_gpu[:,0]]\n",
    "# sum the features\n",
    "sum_features_gpu = torch.sum(valid_features_gpu, dim=1)\n",
    "sumsum_features_gpu = torch.sum(sum_features_gpu, dim=0)\n",
    "print(sumsum_features_gpu)\n",
    "# mean the features\n",
    "mean_features_gpu = torch.mean(valid_features_gpu, dim=1)\n",
    "mean_features = mean_features_gpu.detach().numpy()\n",
    "valid_features = valid_features_gpu.detach().numpy().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) (64,)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, param in model.named_parameters():\n",
    "    # print(name, param.shape)\n",
    "    if name == 'vfe.pfn_layers.0.linear.weight':\n",
    "        vfe_pfn_weight = param.detach().cpu().numpy()\n",
    "    elif name == 'vfe.pfn_layers.0.norm.weight':\n",
    "        vfe_pfn_norm_weight = param.detach().cpu().numpy()\n",
    "    elif name == 'vfe.pfn_layers.0.norm.bias':\n",
    "        vfe_pfn_norm_bias = param.detach().cpu().numpy()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(vfe_pfn_norm_weight.shape, mean_features.shape)\n",
    "print(vfe_pfn_weight.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAND 0.16488872757028727 10.354903324069507\n",
      "MEAN 0.023988719970460922 11.17933\n"
     ]
    }
   ],
   "source": [
    "# calcuate the  Pearson correlation coefficient (PCC) of the features\n",
    "def cal_PCC(a,b):\n",
    "    # a,b are two vectors, both are numpy array(64,)\n",
    "    a_mean = np.mean(a)\n",
    "    b_mean = np.mean(b)\n",
    "    a_std = np.std(a)\n",
    "    b_std = np.std(b)\n",
    "    a = (a - a_mean) / a_std\n",
    "    b = (b - b_mean) / b_std\n",
    "\n",
    "    pcc = np.sum(a * b) / (64 - 1)\n",
    "    return pcc\n",
    "\n",
    "def cal_DIST(a,b):\n",
    "    # a,b are two vectors, both are numpy array(64,)\n",
    "    a_mean = np.mean(a)\n",
    "    b_mean = np.mean(b)\n",
    "    a_std = np.std(a)\n",
    "    b_std = np.std(b)\n",
    "    a = (a - a_mean) / a_std\n",
    "    b = (b - b_mean) / b_std\n",
    "\n",
    "    dist = np.sqrt(np.sum(np.square(a - b)))\n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "# random a 64 dim vector\n",
    "random_vector = np.random.rand(64)\n",
    "print('RAND',cal_PCC(random_vector, vfe_pfn_norm_weight), cal_DIST(random_vector, vfe_pfn_norm_weight))\n",
    "\n",
    "\n",
    "new_valid_features = []\n",
    "for i in range(valid_features.shape[0]):\n",
    "    if np.sum(valid_features[i]) != 0:\n",
    "        new_valid_features.append(valid_features[i])\n",
    "\n",
    "new_mean_features = np.mean(new_valid_features, axis=0)\n",
    "print('MEAN',cal_PCC(new_mean_features, vfe_pfn_norm_weight), cal_DIST(new_mean_features, vfe_pfn_norm_weight))\n",
    "\n",
    "pccs , dists = [], []\n",
    "\n",
    "for f in new_valid_features:\n",
    "    norm_f = (f - np.mean(f)) / np.std(f)\n",
    "    pcc = cal_PCC(norm_f, vfe_pfn_norm_weight)\n",
    "    dist = cal_DIST(norm_f, vfe_pfn_norm_weight)\n",
    "    pccs.append(pcc)\n",
    "    dists.append(dist)\n",
    "\n",
    "pillar_features = data_dict['pillar_features'].detach().cpu().numpy()\n",
    "\n",
    "pccs_a, dists_a = [], []\n",
    "for f in pillar_features:\n",
    "    norm_f = (f - np.mean(f)) / np.std(f)\n",
    "    pcc = cal_PCC(norm_f, vfe_pfn_norm_weight)\n",
    "    dist = cal_DIST(norm_f, vfe_pfn_norm_weight)\n",
    "    pccs_a.append(pcc)\n",
    "    dists_a.append(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAILD\n",
      "PCC 0.023941956499896985 0.0018214784232850265\n",
      "DIST 11.179589 0.010264958\n",
      "ALL\n",
      "PCC -0.010363435207039595 0.06112889185630575\n",
      "DIST 11.366174 0.34042546\n"
     ]
    }
   ],
   "source": [
    "print('VAILD')\n",
    "print('PCC', np.mean(pccs), np.std(pccs))\n",
    "print('DIST', np.mean(dists), np.std(dists))\n",
    "\n",
    "print('ALL')\n",
    "print('PCC', np.mean(pccs_a), np.std(pccs_a))\n",
    "print('DIST', np.mean(dists_a), np.std(dists_a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[574 299]\n",
      " [574 300]\n",
      " [574 301]\n",
      " [574 302]\n",
      " [574 303]\n",
      " [575 299]\n",
      " [575 300]\n",
      " [575 301]\n",
      " [575 302]\n",
      " [575 303]\n",
      " [576 299]\n",
      " [576 300]\n",
      " [576 301]\n",
      " [576 302]\n",
      " [576 303]]\n",
      "[ALL]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[MODEL]\n",
      "[ 4.66224015e-01  5.89123905e-01  7.30595231e-01  6.23314559e-01\n",
      "  5.01648188e-01  4.40576851e-01  3.88421327e-01  6.61048591e-02\n",
      "  3.63332897e-01  8.64318684e-02  1.25650272e-01  3.84412683e-03\n",
      "  1.56942885e-02  1.28675520e-01  6.96303666e-01  7.34482229e-01\n",
      "  3.24085832e-01  3.16470228e-02  1.53639704e-01  4.19468910e-01\n",
      "  2.17271030e-01  9.88197848e-02  9.35283750e-02  1.76510036e-01\n",
      "  2.57483035e-01  6.85205936e-01  1.62106827e-01  4.84209329e-01\n",
      "  3.25548828e-01  2.23842114e-01  3.33975077e-01  7.75968492e-01\n",
      "  2.57090688e-01 -5.62431850e-03  1.01968706e-01  6.19319379e-01\n",
      "  9.21009064e-01  2.79301882e-01  4.59435672e-01  3.23516011e-01\n",
      "  9.09003913e-01  1.78123415e-01  2.78511971e-01  1.15416363e-01\n",
      "  2.65900970e-01  5.70483267e-01 -4.96540975e-04  1.88652620e-01\n",
      "  8.06017742e-02  7.74151683e-02  9.11088586e-01  6.62768483e-01\n",
      "  2.04871267e-01  7.22327173e-01  1.50152352e-02  6.28980935e-01\n",
      "  1.33559620e+00  6.26250729e-02  2.02321276e-01  4.58050817e-01\n",
      "  1.45316303e-01  1.18790388e-01  7.31995702e-01  6.05977476e-01]\n"
     ]
    }
   ],
   "source": [
    "# load data_dict['spatial_features'] to cpu\n",
    "spatial_features = data_dict['spatial_features'].detach().cpu().numpy()\n",
    "spatial_features = spatial_features[0]\n",
    "print(feature_idx)\n",
    "valid_features = np.array(spatial_features[:,  feature_idx[:,1], feature_idx[:,0]])\n",
    "\n",
    "# print(spatial_features.shape)\n",
    "\n",
    "\n",
    "# valid_features = np.array(spatial_features[:, feature_idx[:,1], feature_idx[:,0]])\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    # print(name, param.shape)\n",
    "    if name == 'vfe.pfn_layers.0.linear.weight':\n",
    "        vfe_pfn_weight = param.detach().cpu().numpy()\n",
    "    elif name == 'vfe.pfn_layers.0.norm.weight':\n",
    "        vfe_pfn_norm_weight = param.detach().cpu().numpy()\n",
    "    elif name == 'vfe.pfn_layers.0.norm.bias':\n",
    "        vfe_pfn_norm_bias = param.detach().cpu().numpy()\n",
    "    else:\n",
    "        pass\n",
    "all_features = np.sum(spatial_features, axis=0)\n",
    "print(\"[ALL]\")\n",
    "print(all_features)\n",
    "\n",
    "\n",
    "print(\"[MODEL]\")\n",
    "\n",
    "print(vfe_pfn_norm_weight)\n",
    "\n",
    "# print(\"[DATA]\")\n",
    "# # print(valid_features)\n",
    "# for f in valid_features:\n",
    "#     print(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07383359851122767 0.07180815711723669\n",
      "0.15827617686433865 0.010247387089730104\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "X_train = vfe_pfn_weight.T\n",
    "X_test = valid_features.T\n",
    "clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.05)\n",
    "clf.fit(X_train)\n",
    "\n",
    "distances = np.abs(clf.decision_function(X_test))\n",
    "print(np.mean(distances), np.std(distances))\n",
    "\n",
    "all_features = data_dict['pillar_features'].detach().cpu().numpy()\n",
    "distances = np.abs(clf.decision_function(all_features))\n",
    "print(np.mean(distances), np.std(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(model.vfe.pfn_layers[0].linear.weight.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
